# .github/workflows/deploy_datasets.yml

name: Validar y Desplegar Datasets de GeoDOM

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'datasets/**'
  
  push:
    branches: [ main ]
    paths:
      - 'datasets/**'

jobs:
  # JOB 1: VALIDACIÓN (Sin cambios)
  validate:
    name: Validar Archivos del Pull Request
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del Repositorio
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Instalar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Validar Archivos Modificados en PR
        run: |
          MODIFIED_FILES=$(git diff --name-only origin/main...HEAD | grep '^datasets/.*\.\(json\|csv\|geojson\|topojson\|xlsx\)$' || true)
          if [ -z "$MODIFIED_FILES" ]; then
            echo "No hay archivos de dataset relevantes modificados para validar."
          else
            echo "Validando los siguientes archivos:"
            echo "$MODIFIED_FILES"
            for file in $MODIFIED; do
              echo "Validando $file"
              python validate_geodom_dataset.py "$file"
            done
          fi

  # JOB 2: SUBIDA A R2 (Con el paso de instalación corregido)
  upload:
    name: Subir Archivos a Cloudflare R2
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del Repositorio
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Instalar o Actualizar AWS CLI v2
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install --update

      - name: Verificar versión de AWS CLI
        run: aws --version

      - name: Subir Archivos Modificados a R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          MODIFIED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep '^datasets/.*\.\(json\|csv\|geojson\|topojson\|xlsx\)$' || true)

          if [ -z "$MODIFIED_FILES" ]; then
            echo "No hay archivos de dataset relevantes en este push para subir."
            exit 0
          fi
          
          echo "Subiendo los siguientes archivos a R2:"
          echo "$MODIFIED_FILES"

          for file in $MODIFIED_FILES; do
            filename=$(basename "$file")
            dest_path="datasets/$filename"
            
            echo "Subiendo '$file' a R2 como '$dest_path'"
            aws s3 cp "$file" "s3://$R2_BUCKET/$dest_path" --endpoint-url "$R2_ENDPOINT"
          done
          echo "Subida completada."