# .github/workflows/deploy_datasets.yml

name: Validar y Desplegar Datasets de GeoDOM

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'datasets/**'
  
  push:
    branches: [ main ]
    paths:
      - 'datasets/**'

jobs:
  # JOB 1: VALIDACIÓN (Solo para Pull Requests)
  validate:
    name: Validar Archivos del Pull Request
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del Repositorio
        uses: actions/checkout@v4
        with:
          # --- ¡ESTA ES LA SOLUCIÓN! ---
          # '0' descarga todo el historial, necesario para comparar con 'main'.
          fetch-depth: 0

      - name: Instalar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Validar Archivos Modificados en PR
        run: |
          MODIFIED_FILES=$(git diff --name-only origin/main...HEAD | grep '^datasets/.*\.\(json\|csv\|geojson\|topojson\|xlsx\)$' || true)
          # ... resto de tu lógica de validación ...
          if [ -z "$MODIFIED_FILES" ]; then
            echo "No hay archivos de dataset relevantes modificados para validar."
          else
            echo "Validando los siguientes archivos:"
            echo "$MODIFIED_FILES"
            for file in $MODIFIED_FILES; do
              if [[ "$file" == *.json ]]; then
                echo "Validando metadatos en $file"
                # python validate_geodom_dataset.py "$file"
              fi
            done
          fi

  # JOB 2: SUBIDA A R2 (Solo para Push a Main)
  upload:
    name: Subir Archivos a Cloudflare R2
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del Repositorio
        uses: actions/checkout@v4
        with:
          # --- ¡ESTA ES LA SOLUCIÓN! ---
          # También se necesita aquí para comparar el commit 'before' y 'after' del push.
          fetch-depth: 0

      - name: Instalar AWS CLI
        run: pip install awscli

      - name: Subir Archivos Modificados a R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          MODIFIED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep '^datasets/.*\.\(json\|csv\|geojson\|topojson\|xlsx\)$' || true)

          if [ -z "$MODIFIED_FILES" ]; then
            echo "No hay archivos de dataset relevantes en este push para subir."
            exit 0
          fi
          
          echo "Subiendo los siguientes archivos a R2:"
          echo "$MODIFIED_FILES"

          for file in $MODIFIED_FILES; do
            filename=$(basename "$file")
            dest_path="datasets/$filename"
            
            echo "Subiendo '$file' a R2 como '$dest_path'"
            aws s3 cp "$file" "s3://$R2_BUCKET/$dest_path" --endpoint-url "$R2_ENDPOINT"
          done
          echo "Subida completada."